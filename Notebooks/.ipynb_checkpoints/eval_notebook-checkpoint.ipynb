{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/iranildo/anaconda3/envs/paic/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/iranildo/anaconda3/envs/paic/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/iranildo/anaconda3/envs/paic/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/iranildo/anaconda3/envs/paic/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/iranildo/anaconda3/envs/paic/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/iranildo/anaconda3/envs/paic/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/iranildo/anaconda3/envs/paic/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/iranildo/anaconda3/envs/paic/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/iranildo/anaconda3/envs/paic/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/iranildo/anaconda3/envs/paic/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/iranildo/anaconda3/envs/paic/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/iranildo/anaconda3/envs/paic/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics\n",
    "from scipy.stats import norm as dist_model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2ac_predict(model, data, top_n, vote_n=1):\n",
    "    test_X, test_X1=data['test_X0'], data['test_X1']\n",
    "    y_pred=[]\n",
    "    for ix in range(test_X1.shape[1]): #through all candidate classes\n",
    "        if vote_n>1:\n",
    "            n_pred=[]\n",
    "            for jx in range(-vote_n, 0):\n",
    "                n_pred.append(model.predict([test_X, test_X1[:,ix,jx].reshape(-1,1) ] ) )\n",
    "            n_pred=np.concatenate(n_pred, 1)\n",
    "        else:\n",
    "            n_pred=model.predict([test_X, test_X1[:,ix,-top_n:] ] )\n",
    "        y_pred.append( np.expand_dims(n_pred, 1) )\n",
    "    y_pred=np.concatenate(y_pred, 1)\n",
    "    y_pred=y_pred[:,:,-vote_n:].sum(-1)/float(vote_n)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_predict(model, data, model_type):\n",
    "    if \"mlp\" in model_type:\n",
    "        y_pred=model.predict(data['test_X0'])\n",
    "    else:\n",
    "        y_pred=model.predict(data['test_idx_X0']) \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_thres(model, data, model_type, scale = 2.):\n",
    "    train_y = data['train_set_Y']\n",
    "    if \"mlp\" in model_type:\n",
    "        train_pred = model.predict(data['train_set_X'])\n",
    "    else:\n",
    "        train_pred = model.predict(data['train_set_idx_X'])\n",
    "    #print train_y.shape, train_pred.shape \n",
    "    def fit(prob_pos_X):\n",
    "        prob_pos = [p for p in prob_pos_X]+[2-p for p in prob_pos_X]\n",
    "        pos_mu, pos_std = dist_model.fit(prob_pos)\n",
    "        return pos_std\n",
    "    stds = []\n",
    "    for c in range(train_pred.shape[-1]):\n",
    "        idx = [train_y == c]\n",
    "        c_pred = train_pred[idx]\n",
    "        c_prob = c_pred[:,c]\n",
    "        std = fit(c_prob)\n",
    "        stds.append(std)\n",
    "    thres = [max(0.5, 1. - scale * std) for std in stds]\n",
    "    return thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, thres=0.5, rejection=False, mode=\"weighted\"):\n",
    "    if rejection:\n",
    "        if isinstance(thres, list):\n",
    "            reject_pred = []\n",
    "            for p in y_pred:# loop every test prediction\n",
    "                max_class = np.argmax(p)# predicted class\n",
    "                max_value = np.max(p)# predicted probability           \n",
    "                if max_value > thres[max_class]:\n",
    "                    reject_pred.append(0)#predicted probability is greater than threshold, accept\n",
    "                else:\n",
    "                    reject_pred.append(1)#otherwise, reject\n",
    "            y_pred=np.concatenate([y_pred, np.expand_dims(reject_pred, 1) ], 1) \n",
    "        else:\n",
    "            y_pred=np.concatenate([y_pred, np.expand_dims(y_pred.max(axis=1)<=thres, 1) ], 1)\n",
    "    else:\n",
    "        keep_idx=(y_true!=y_true.max() )\n",
    "        y_pred=y_pred[keep_idx]\n",
    "        y_true=y_true[keep_idx]\n",
    "    y_pred=y_pred.argmax(axis=1)\n",
    "    return sklearn.metrics.f1_score(y_true, y_pred, average=mode), y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_evaluate(config):\n",
    "    set_modes=config[\"set_modes\"] #[\"test_25\", \"test_50\", \"test_75\"]\n",
    "    db=config[\"db\"] #\"amazon\" \n",
    "    out_dir=config[\"out_dir\"]\n",
    "    model_type=config[\"model_type\"]\n",
    "    doc_eval=\"DOC\" in model_type \n",
    "    if not doc_eval:\n",
    "        top_n=config[\"top_n\"] #10\n",
    "        vote_n=config[\"vote_n\"] #1 #typically 1, we disable manual vote; when top_n=1, we optionally vote\n",
    "\n",
    "    scores={}\n",
    "    for set_mode in set_modes:\n",
    "        data=np.load(\"../\"+db+\"/data/\"+set_mode+\"_idx.npz\")\n",
    "        sess=tf.Session()\n",
    "        K.set_session(sess)\n",
    "        if doc_eval:\n",
    "            model_fn=out_dir+\"eval_\"+set_mode+\".h5\"\n",
    "            model=keras.models.load_model(model_fn)\n",
    "        else:\n",
    "            model_fn=out_dir+\"eval.h5\"\n",
    "            model=keras.models.load_model(model_fn)\n",
    "            model.get_layer(\"embedding_1\").set_weights([np.vstack([data['train_rep'], np.zeros((90000, 512))]) ])\n",
    "        \n",
    "        thres=0.5\n",
    "        if doc_eval:\n",
    "            y_pred=doc_predict(model, data, model_type)\n",
    "            gaus_thres=doc_thres(model, data, model_type)\n",
    "        else:\n",
    "            y_pred=l2ac_predict(model, data, top_n, vote_n)\n",
    "            \n",
    "        weighted_f1, _, _=evaluate(data['test_Y'], y_pred, thres=thres, rejection=True, mode=\"weighted\")\n",
    "        macro_f1, _, _=evaluate(data['test_Y'], y_pred, thres=thres, rejection=True, mode=\"macro\")\n",
    "        micro_f1, _, _=evaluate(data['test_Y'], y_pred, thres=thres, rejection=True, mode=\"micro\")\n",
    "        scores[set_mode]={'weighted_f1': weighted_f1, 'macro_f1': macro_f1, 'micro_f1': micro_f1}\n",
    "        if doc_eval:\n",
    "            weighted_f1, _, _=evaluate(data['test_Y'], y_pred, thres=gaus_thres, rejection=True, mode=\"weighted\")\n",
    "            macro_f1, _, _=evaluate(data['test_Y'], y_pred, thres=gaus_thres, rejection=True, mode=\"macro\")\n",
    "            micro_f1, _, _=evaluate(data['test_Y'], y_pred, thres=gaus_thres, rejection=True, mode=\"micro\")\n",
    "            scores[set_mode+\"_gaus\"]={'weighted_f1': weighted_f1, 'macro_f1': macro_f1, 'micro_f1': micro_f1}\n",
    "            \n",
    "        K.clear_session() \n",
    "    with open(out_dir+\"eval.json\", \"w\") as fw:\n",
    "        json.dump(scores, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 0, 'batch_size': 256, 'model_type': 'l2ac', 'top_n': 5, 'ncls': 9, 'set_mode': 'train1', 'db': 'amazon', 'out_dir': '../runs/l2ac_5_9/0/', 'set_modes': ['test_50', 'test_75'], 'vote_n': 1}\n"
     ]
    }
   ],
   "source": [
    "path = \"../runs/l2ac_5_9/0/config.json\"\n",
    "with open(path) as f:\n",
    "    config=json.load(f)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_50\n",
      "test_idx_X0 (5000, 120)\n",
      "train_set_Y (5000,)\n",
      "train_set_idx_X (5000, 120)\n",
      "train_rep (10000, 512)\n",
      "test_X0 (5000, 512)\n",
      "test_X1 (5000, 50, 99)\n",
      "test_Y (5000,)\n",
      "train_set_X (5000, 512)\n",
      "\n",
      "test_75\n",
      "test_idx_X0 (5000, 120)\n",
      "train_set_Y (7500,)\n",
      "train_set_idx_X (7500, 120)\n",
      "train_rep (10000, 512)\n",
      "test_X0 (5000, 512)\n",
      "test_X1 (5000, 75, 99)\n",
      "test_Y (5000,)\n",
      "train_set_X (7500, 512)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data=np.load(\"../\"+db+\"/data/\"+set_modes[0]+\"_idx.npz\")\\nprint(data.files)\\nprint(data[\\'test_X0\\'].shape)\\nprint(data[\\'test_X0\\'])'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_modes = config['set_modes']\n",
    "db = config['db']\n",
    "for set_mode in set_modes:\n",
    "    data=np.load(\"../\"+db+\"/data/\"+set_mode+\"_idx.npz\")\n",
    "    print(set_mode)\n",
    "    for ident,key in enumerate(data):\n",
    "        print(key,data[key].shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_evaluate(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
